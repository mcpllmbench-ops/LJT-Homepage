---
title: "In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation"
collection: publications
category: conferences
permalink: /publication/2024-07-21-context-sharpness
excerpt: 'Co-authored paper published at ICML 2024 presenting an inner representation perspective for hallucination mitigation in large language models.'
date: 2024-07-21
venue: 'ICML 2024'
paperurl: 'https://proceedings.mlr.press/'
citation: 'Chen, S., Xiong, M., Liu, J., Wu, Z., Xiao, T., Gao, S., & He, J. (2024). "In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation." <i>Proceedings of the 41st International Conference on Machine Learning (ICML)</i>.'
---

This paper presents a novel approach to mitigating hallucinations in large language models by analyzing in-context sharpness as alerts. The research provides an inner representation perspective on understanding and reducing hallucinations in language model outputs.

The contents above will be part of a list of publications, if the user clicks the link for the publication than the contents of section will be rendered as a full page, allowing you to provide more information about the paper for the reader. When publications are displayed as a single page, the contents of the above "citation" field will automatically be included below this section in a smaller font.